{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f7f7a-6ecf-444c-8bf8-c5ad57883640",
   "metadata": {},
   "source": [
    "![logo](assets/logo.png \"animâˆž\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457d09d-10fc-4cd3-9932-b00b4c58b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.demo_diffusion import GaussianDiffusion\n",
    "#from lafan.preprocess import Normalizer\n",
    "from lafan.skeleton import (Skeleton, sk_joints_to_remove, sk_offsets, sk_parents, amass_offsets)\n",
    "import imageio\n",
    "\n",
    "import pickle\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from tempfile import TemporaryDirectory\n",
    "from IPython.display import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e0bab-0f51-44f2-81e9-303f2f2e8423",
   "metadata": {},
   "source": [
    "## Utility functions for processing, transforming, and plotting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb277fa-2fa2-47a5-96b2-a1c031b19044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPosQ(posq):\n",
    "    # Array comes in the format:\n",
    "    # seq_len x (4 contact labels + 3*joint_num position DoFs + 4*joint_num quaternion DoFs + 20 phase variables)\n",
    "    joint_num = 22\n",
    "    contact = posq[:, :4] > 0.5\n",
    "    pos = posq[:,4:4+joint_num*3]\n",
    "    orn = posq[:, 4+joint_num*3:]\n",
    "    phase = posq[:,4+joint_num*7:]\n",
    "    pos = pos.reshape((pos.shape[0], -1, 3))\n",
    "    orn = orn.reshape((orn.shape[0], -1, 4))\n",
    "    return pos, orn, phase, contact\n",
    "\n",
    "def global_to_local(orn, x, skeleton_mocap):\n",
    "    root_pos_tensor = torch.Tensor(x[:,0]).unsqueeze(0).cuda()\n",
    "    local_orn = skeleton_mocap.global_to_local(orn)\n",
    "    local_orn_tensor = torch.Tensor(local_orn).unsqueeze(0).cuda() # 1 x s x j x 4\n",
    "    global_pos, _ = skeleton_mocap.forward_kinematics_with_rotation(local_orn_tensor, root_pos_tensor)\n",
    "    return global_pos, local_orn, root_pos_tensor\n",
    "\n",
    "def set_line_data_3d(line, x):\n",
    "    line.set_data(x[:, :2].T)\n",
    "    line.set_3d_properties(x[:, 2])\n",
    "        \n",
    "def plot_single_pose(\n",
    "    num, poses, lines, ax, skeleton\n",
    "):\n",
    "    parent_idx = skeleton.parents()\n",
    "\n",
    "    pose = poses[num]\n",
    "    for i, (p, line) in enumerate(zip(parent_idx, lines)):\n",
    "        # don't plot root\n",
    "        if i == 0:\n",
    "            continue\n",
    "        # stack to create a line\n",
    "        data = np.stack((pose[i], pose[p]), axis=0)\n",
    "        set_line_data_3d(line, data)\n",
    "\n",
    "    x_min = pose[:, 0].min()\n",
    "    x_max = pose[:, 0].max()\n",
    "\n",
    "    y_min = pose[:, 1].min()\n",
    "    y_max = pose[:, 1].max()\n",
    "\n",
    "    z_min = pose[:, 2].min()\n",
    "    z_max = pose[:, 2].max()\n",
    "    \n",
    "    xdiff = x_max - x_min\n",
    "    ydiff = y_max - y_min\n",
    "    zdiff = z_max - z_min\n",
    "    \n",
    "    xcenter = x_min + xdiff/2\n",
    "    ycenter = y_min + ydiff/2\n",
    "    zcenter = z_min + zdiff/2\n",
    "    \n",
    "    biggestdiff = max([xdiff, ydiff, zdiff])\n",
    "    step = biggestdiff/2\n",
    "    x_min, x_max = xcenter - step, xcenter + step\n",
    "    y_min, y_max = ycenter - step, ycenter + step\n",
    "    z_min, z_max = zcenter - step, zcenter + step    \n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_xlabel(\"$X$ Axis\")\n",
    "\n",
    "    ax.set_ylim(z_min, z_max)\n",
    "    ax.set_ylabel(\"$Y$ Axis\")\n",
    "\n",
    "    ax.set_zlim(y_min, y_max)\n",
    "    ax.set_zlabel(\"$Z$ Axis\")\n",
    "\n",
    "    plt.draw()\n",
    "    \n",
    "def plot(sample, skeleton_mocap, out):\n",
    "    Path(out).mkdir(parents=True, exist_ok=True)\n",
    "    for i, (label, sequence) in enumerate(zip(sample[\"labels\"], sample[\"samples\"])):\n",
    "        x = sequence\n",
    "        x, orn, phase, contact = splitPosQ(x)\n",
    "        num_steps = sequence.shape[0]\n",
    "        \n",
    "        # convert orn from global to local\n",
    "        global_pos, local_orn, root_pos_tensor = global_to_local(orn, x, skeleton_mocap)\n",
    "        root_pos_tensor = root_pos_tensor.detach().cpu().numpy()\n",
    "        x2 = global_pos.squeeze().cpu().numpy()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "        \n",
    "        # Create lines initially without data\n",
    "        lines = [ax.plot([], [], [], zorder=10)[0] for _ in skeleton_mocap.parents()]\n",
    "        \n",
    "        file_out = './{}{}.gif'.format(label, i)\n",
    "        \n",
    "        x2[:,:,(1, 2)] = x2[:,:,(2,1)]\n",
    "        \n",
    "        anim = animation.FuncAnimation(\n",
    "            fig, plot_single_pose, num_steps, fargs=(x2, lines, ax, skeleton_mocap), interval=1000//30)\n",
    "        gifname = os.path.join(out, file_out)\n",
    "        anim.save(gifname)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953e184-dd4d-4570-9151-c61d90114ad1",
   "metadata": {},
   "source": [
    "## Constants setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116ae51-2c5b-49c3-80cd-a8ef5eec8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find device\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Skeleton\n",
    "offset = sk_offsets\n",
    "skeleton_mocap = Skeleton(offsets=offset, parents=sk_parents, device=device)\n",
    "skeleton_mocap.remove_joints(sk_joints_to_remove)\n",
    "\n",
    "num_phases = 0\n",
    "num_foot_joints = 2\n",
    "pos_dim = 22 * 3\n",
    "rot_dim = 22 * 4\n",
    "repr_dim = 2 * num_foot_joints + pos_dim + rot_dim + 2 * num_phases\n",
    "\n",
    "# unfortunately you can't change this, since it's baked into the onnx model\n",
    "sample_size = 4\n",
    "\n",
    "# auxiliary trained hyperparameters\n",
    "UNC_LABEL, le, normalizer, horizon, num_labels = pickle.load(open(\"demo_info.pkl\",\"rb\"))\n",
    "\n",
    "# trained model, compiled into a fast onnx graph\n",
    "model = ort.InferenceSession('unet.onnx', providers=['CUDAExecutionProvider'])\n",
    "\n",
    "diffusion = GaussianDiffusion(model, \n",
    "                      horizon, \n",
    "                      repr_dim, \n",
    "                      skeleton=skeleton_mocap, \n",
    "                      predict_epsilon=False, \n",
    "                      unc_token=UNC_LABEL,\n",
    "                      n_timesteps=1000,\n",
    "                      guidance_weight=3\n",
    "                     )\n",
    "diffusion.to(device)\n",
    "diffusion.eval()\n",
    "# generated shape\n",
    "shape = (sample_size, 1, horizon-1, repr_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6417323-3403-42ea-bbfd-f5ca9ad20e38",
   "metadata": {},
   "source": [
    "## Let's generate a sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c55514-4263-4e14-9698-069056ccbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random semantic labels\n",
    "y = torch.randint(0, num_labels, (sample_size, 1))\n",
    "# or, you can set them manually with names from the LAFAN dataset as follows\n",
    "#y = torch.Tensor(le.transform([\"aiming\"] * sample_size)).int()\n",
    "y = y.squeeze()\n",
    "print(\"Generating a sample for classes {}\".format([le.inverse_transform([x.cpu().numpy()])[0] for x in y]))\n",
    "sample = diffusion(shape, y).squeeze(1)\n",
    "sample = normalizer.unnormalize(sample.cpu())\n",
    "\n",
    "sample = sample.detach().cpu().numpy()\n",
    "out = {\n",
    "        \"labels\":[le.inverse_transform([x.cpu().numpy()])[0] for x in y],\n",
    "        \"samples\":sample,\n",
    "        \"constraints\":None\n",
    "      }\n",
    "print(\"Plotting samples\")\n",
    "plot(out, skeleton_mocap, \"out\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8844b10-2f11-43dd-9e4b-12f8ffc342b1",
   "metadata": {},
   "source": [
    "## Pick a random gif to show*\n",
    "\n",
    "*Results vary lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa63d2-1e00-4073-9d11-41c70e81ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"out/*.gif\")\n",
    "Image(open(random.choice(files),'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf623d0-be42-4e02-a6ad-04bc3e798470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
